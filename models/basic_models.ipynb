{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to get a general idea of how different transformations and models perform, without changing their hyperparameters.\n",
    "<br><br>\n",
    "Models and transformations that lead to very poor predictions will no be used in future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important libraries\n",
    "\n",
    "# transformations library\n",
    "from transformations import minimum, geometric, minimum2D, geometric2D\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "# loading data\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# other modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get base_dataset\n",
    "data_path = \"TrainTestData/train_data.pickle\"\n",
    "data = pickle.load(open(data_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models and their names (names only to make prints easier)\n",
    "models = [\n",
    "    {\"name\": \"RandomForest\", \"classifier\": RandomForestClassifier(n_jobs=-1), \"scale\": False},\n",
    "    {\"name\": \"LogisticRegression\", \"classifier\": SGDClassifier(loss=\"log_loss\"), \"scale\": True},\n",
    "    {\"name\": \"SVM\", \"classifier\": SVC(), \"scale\": True},\n",
    "    {\"name\": \"KNN\", \"classifier\": KNeighborsClassifier(), \"scale\": True}\n",
    "]\n",
    "\n",
    "# list of changed_models and their names (names only to make prints easier)\n",
    "changed_datasets = [\n",
    "    {\"name\": \"Minimum 3D\", \"transformation\": minimum, \"dataset\": {}},\n",
    "    {\"name\": \"Geometric 3D\", \"transformation\": geometric, \"dataset\": {}},\n",
    "    {\"name\": \"Minimum 2D\", \"transformation\": minimum2D, \"dataset\": {}},\n",
    "    {\"name\": \"Geometric 2D\", \"transformation\": geometric2D, \"dataset\": {}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates weighted_accuracy\n",
    "# weights are basead on the frequency of the letters in the portuguese alphabet \n",
    "# source: https://pt.wikipedia.org/wiki/Alfabeto_portugu%C3%AAs#Frequ%C3%AAncia_da_ocorr%C3%AAncia_de_letras\n",
    "# H, K, J, X and Z are not present\n",
    "LETTERS_FREQUENCY = [\n",
    "    14.63,\n",
    "    1.04,\n",
    "    3.88,\n",
    "    5.01,\n",
    "    12.57,\n",
    "    1.02,\n",
    "    1.30,\n",
    "    6.18,\n",
    "    2.78,\n",
    "    4.74,\n",
    "    5.05,\n",
    "    10.73,\n",
    "    2.52,\n",
    "    1.20,\n",
    "    6.53,\n",
    "    7.81,\n",
    "    4.34,\n",
    "    4.63,\n",
    "    1.67,\n",
    "    0.01,\n",
    "    0.01,\n",
    "]\n",
    "def weighted_accuracy(y_true, y_pred):\n",
    "    recall_array = recall_score(y_true, y_pred, average=None)\n",
    "    weights_total = 0\n",
    "    result = 0\n",
    "    for recall, weight in zip(recall_array, LETTERS_FREQUENCY):\n",
    "        weights_total += weight\n",
    "        result += recall * weight\n",
    "    return result / weights_total\n",
    "weighted_accuracy_score = make_scorer(weighted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that train the models\n",
    "# returns the model trained and its accuracy in cross val score\n",
    "# if feature scaling is necessary, makes minmax\n",
    "def train_model (model, data, scaling=False, cv=5):\n",
    "    if scaling:\n",
    "        scaler = MinMaxScaler()\n",
    "        features = scaler.fit_transform(data[\"features\"])\n",
    "    else:\n",
    "        features = data[\"features\"]\n",
    "    X = features\n",
    "    y = data[\"labels\"]\n",
    "\n",
    "    # train and test model with cross val score\n",
    "    score = np.mean(cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring=weighted_accuracy_score))\n",
    "\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the necessary transformations for training\n",
    "for option in changed_datasets:\n",
    "    new_features = []\n",
    "    for observation in data[\"features\"]:\n",
    "        new_features.append(option[\"transformation\"](observation))\n",
    "    option[\"dataset\"][\"features\"] = new_features\n",
    "    option[\"dataset\"][\"labels\"] = data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Minimum 3D 0.9407256167096127\n",
      "RandomForest Geometric 3D 0.9031747908460657\n",
      "RandomForest Minimum 2D 0.9442522269748361\n",
      "RandomForest Geometric 2D 0.9178894399955378\n",
      "LogisticRegression Minimum 3D 0.8372268668761362\n",
      "LogisticRegression Geometric 3D 0.6775464842641636\n",
      "LogisticRegression Minimum 2D 0.7727500652391159\n",
      "LogisticRegression Geometric 2D 0.5784093080234257\n",
      "SVM Minimum 3D 0.922297394557531\n",
      "SVM Geometric 3D 0.8739441226691611\n",
      "SVM Minimum 2D 0.9177141723759805\n",
      "SVM Geometric 2D 0.8689468596792571\n",
      "KNN Minimum 3D 0.9114483307833072\n",
      "KNN Geometric 3D 0.8422670308200975\n",
      "KNN Minimum 2D 0.9223405590970337\n",
      "KNN Geometric 2D 0.876452695802962\n"
     ]
    }
   ],
   "source": [
    "# trains all models and prints their results\n",
    "for model in models:\n",
    "    for dataset in changed_datasets:\n",
    "        _, accuracy = train_model(model[\"classifier\"], dataset[\"dataset\"], scaling=model[\"scale\"])\n",
    "        print(model[\"name\"], dataset[\"name\"], accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression models had the worst performance, and since is lower than the other models by about 10 p.p, it will not be used in further analysis.\n",
    "<br><br>\n",
    "The other models and transformations had good performances overall.\n",
    "<br><br>\n",
    "Therefore, we will explore more the models RandomForest, SVM and KNN, as well as the transformations Minimum and Geometric.\n",
    "<br><br>\n",
    "In Random Forest and KNN, 2D transformations performed better than 3D, but the inverse happened in SVM. Sincethe differences are quite small, we will continue to test all of them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
