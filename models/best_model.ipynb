{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we trained a lot of different models, it's time to select the best one. In this notebook, we will try 4 different models:\n",
    "- Random Forest: minimum transformation, max_depth = 30 and n_estimators = 100 (performance = 93.91%)\n",
    "- KNN: geometric transformation, n_neighbors = 3, p = 19 and weights = \"distance\" (performance = 94.20%)\n",
    "- SVM: geometric transformation, kernel = \"rbf\", C = 30 and gamma = 5 (performance = 97.02%)\n",
    "- Essemble of the best KNN, the best SVM and the best Random Forest that uses geometric transformation (max_depth = 30 and n_estimators = 200, performance = 91.94%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important libraries\n",
    "\n",
    "# transformations library\n",
    "from transformations import minimum, geometric\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# loading data\n",
    "import pickle\n",
    "\n",
    "# other modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "data_path = \"TrainTestData/train_data.pickle\"\n",
    "data = pickle.load(open(data_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates weighted_accuracy\n",
    "# weights are basead on the frequency of the letters in the portuguese alphabet \n",
    "# source: https://pt.wikipedia.org/wiki/Alfabeto_portugu%C3%AAs#Frequ%C3%AAncia_da_ocorr%C3%AAncia_de_letras\n",
    "# H, K, J, X and Z are not present\n",
    "LETTERS_FREQUENCY = [\n",
    "    14.63,\n",
    "    1.04,\n",
    "    3.88,\n",
    "    5.01,\n",
    "    12.57,\n",
    "    1.02,\n",
    "    1.30,\n",
    "    6.18,\n",
    "    2.78,\n",
    "    4.74,\n",
    "    5.05,\n",
    "    10.73,\n",
    "    2.52,\n",
    "    1.20,\n",
    "    6.53,\n",
    "    7.81,\n",
    "    4.34,\n",
    "    4.63,\n",
    "    1.67,\n",
    "    0.01,\n",
    "    0.01,\n",
    "]\n",
    "def weighted_accuracy(y_true, y_pred):\n",
    "    recall_array = recall_score(y_true, y_pred, average=None)\n",
    "    weights_total = 0\n",
    "    result = 0\n",
    "    for recall, weight in zip(recall_array, LETTERS_FREQUENCY):\n",
    "        weights_total += weight\n",
    "        result += recall * weight\n",
    "    return result / weights_total\n",
    "weighted_accuracy_score = make_scorer(weighted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minumum transformation\n",
    "minimum_X = []\n",
    "for observation in data[\"features\"]:\n",
    "    minimum_X.append(minimum(observation))\n",
    "\n",
    "# Geometric transformation\n",
    "geometric_X = []\n",
    "for observation in data[\"features\"]:\n",
    "    geometric_X.append(geometric(observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Essemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier\n",
    "forest = RandomForestClassifier(max_depth=30, n_estimators=200)\n",
    "knn = KNeighborsClassifier(n_neighbors=3, p=19, weights=\"distance\")\n",
    "svm = SVC(kernel=\"rbf\", C=30, gamma=5)\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[(\"rf\", forest), (\"knn\", knn), (\"svm\", svm)],\n",
    "    voting=\"hard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576984089009951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(voting, geometric_X, data[\"labels\"], cv=5, n_jobs=-1, scoring=weighted_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like this model does not perform as well as the svm model alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Time Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final analysis, where we will compare the best 4 models by their test results and average prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifiers\n",
    "forest = RandomForestClassifier(max_depth=30, n_estimators=200,  n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=3, p=19, weights=\"distance\", n_jobs=-1)\n",
    "svm = SVC(kernel=\"rbf\", C=30, gamma=5)\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[(\"rf\", forest), (\"knn\", knn), (\"svm\", svm)],\n",
    "    voting=\"hard\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_forest = RandomForestClassifier(max_depth=30, n_estimators=100, n_jobs=-1)\n",
    "best_knn = knn\n",
    "best_svm = svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing test data\n",
    "# get dataset\n",
    "data_path = \"TrainTestData/test_data.pickle\"\n",
    "test_data = pickle.load(open(data_path, \"rb\"))\n",
    "\n",
    "# Minumum transformation\n",
    "test_minimum_X = []\n",
    "for observation in test_data[\"features\"]:\n",
    "    test_minimum_X.append(minimum(observation))\n",
    "\n",
    "# Geometric transformation\n",
    "test_geometric_X = []\n",
    "for observation in test_data[\"features\"]:\n",
    "    test_geometric_X.append(geometric(observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier\n",
      "\t Score: 95.61%\n",
      "\t Time: 1.2446 seconds\n",
      "\n",
      "RandomForestClassifier\n",
      "\t Score: 93.61%\n",
      "\t Time: 0.02499 seconds\n",
      "\n",
      "KNeighborsClassifier\n",
      "\t Score: 94.1%\n",
      "\t Time: 0.99616 seconds\n",
      "\n",
      "SVC\n",
      "\t Score: 97.22%\n",
      "\t Time: 0.18441 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "models_info = [\n",
    "    {\"model\": voting, \"data\": \"geometric\"},\n",
    "    {\"model\": best_forest, \"data\": \"minimum\"},\n",
    "    {\"model\": best_knn, \"data\": \"geometric\"},\n",
    "    {\"model\": best_svm, \"data\": \"geometric\"}\n",
    "]\n",
    "\n",
    "for model_info in models_info:\n",
    "    if model_info[\"data\"] == \"geometric\":\n",
    "        train_x = geometric_X\n",
    "        test_x = test_geometric_X\n",
    "    else:\n",
    "        train_x = minimum_X\n",
    "        test_x = test_minimum_X\n",
    "    model = model_info[\"model\"]\n",
    "    model.fit(train_x, data[\"labels\"])\n",
    "    start = time()\n",
    "    y_pred = model.predict(test_x)\n",
    "    end = time()\n",
    "    avg_time = (end - start) / len(test_data)\n",
    "    score = weighted_accuracy(test_data[\"labels\"], y_pred)\n",
    "    print(model.__class__.__name__)\n",
    "    print(f\"\\t Score: {round(100 * score, 2)}%\")\n",
    "    print(f\"\\t Time: {round(avg_time, 5)} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of performance, the SVM model is by far the best, with a score of about 97.22%. However, the other models also have good performances.\n",
    "<br><br>\n",
    "In terms of prediction time, RandomFrest has a time much lower than the others, while SVM time is also fine.\n",
    "<br><br>\n",
    "The choice of best model depends on the equilibrium of these two variables. SVM seems to have a good balance, since it has the best score and the second best time. However, the RandomForest model can be good if sacrifing some performance for time is essential. The KNN and the Voting models don't seem to be good choices, since they are slower and have a worst performance compared to SVM. \n",
    "<br><br>\n",
    "Best Model: SVM with geometric transformation, kernel = \"rbf\", C = 30 and gamma = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
