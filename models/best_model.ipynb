{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to test the best models found during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model library\n",
    "from LibrasModel import LibrasModel, weighted_accuracy_score, weighted_accuracy_scorer\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# loading data\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# other modules\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "train_data = pickle.load(open(\"TrainTestData/train_data.pickle\", \"rb\"))\n",
    "test_data = pickle.load(open(\"TrainTestData/test_data.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the models\n",
    "\n",
    "Check each ipynb to see how we achieved the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"knn1\": KNeighborsClassifier(n_neighbors=3, weights=\"distance\", p=12, n_jobs=-1),\n",
    "    \"knn2\": KNeighborsClassifier(n_neighbors=3, weights=\"distance\", p=11, n_jobs=-1),\n",
    "    \"knn3\": KNeighborsClassifier(n_neighbors=3, weights=\"distance\", p=13, n_jobs=-1),\n",
    "    \"rfc1\": RandomForestClassifier(max_depth=20, n_estimators=200),\n",
    "    \"rfc2\": RandomForestClassifier(max_depth=15, n_estimators=200),\n",
    "    \"rfc3\": RandomForestClassifier(max_depth=20, n_estimators=500),\n",
    "    \"svm1\": SVC(C=20, gamma=5, kernel=\"rbf\"),\n",
    "    \"svm2\": SVC(C=50, gamma=5, kernel=\"rbf\"),\n",
    "    \"svm3\": SVC(C=40, gamma=5, kernel=\"rbf\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(base_model, train_data, test_data, has_z=False):\n",
    "    model = LibrasModel(base_model, has_z=has_z)\n",
    "\n",
    "    X_train = np.array(train_data[\"features\"])\n",
    "    y_train = np.array(train_data[\"labels\"])\n",
    "    X_test = np.array(test_data[\"features\"])\n",
    "    y_test = np.array(test_data[\"labels\"])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    t = time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    t = time() - t\n",
    "\n",
    "    acc_w = weighted_accuracy_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    joblib.dump(model.model, \"model.pkl\")\n",
    "    size = os.path.getsize(\"model.pkl\")\n",
    "    if size < 1024:\n",
    "        size_str = f\"{size}B\"\n",
    "    elif size < 1024 ** 2:\n",
    "        size_str = f\"{round(size / 1024, 2)}KB\"\n",
    "    elif size < 1024 ** 3:\n",
    "        size_str = f\"{round(size / (1024 ** 2), 2)}MB\"\n",
    "    else:\n",
    "        size_str = f\"{round(size / (1024 ** 3), 2)}GB\"\n",
    "\n",
    "    print(f\"Weighted Accuracy: {round(100 * np.mean(acc_w), 2)}%\")\n",
    "    print(f\"Accuracy: {round(100 * np.mean(acc), 2)}%\")\n",
    "    print(f\"Time per prediction: {1000 * t / len(y_test)} ms\")\n",
    "    print(f\"Size (bytes): {size_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn1\n",
      "Weighted Accuracy: 94.17%\n",
      "Accuracy: 93.97%\n",
      "Time per prediction: 0.7903448576356294 ms\n",
      "Size (bytes): 1.45MB\n",
      "--------------------------------------------------\n",
      "knn2\n",
      "Weighted Accuracy: 94.05%\n",
      "Accuracy: 93.88%\n",
      "Time per prediction: 0.8272102020815669 ms\n",
      "Size (bytes): 1.45MB\n",
      "--------------------------------------------------\n",
      "knn3\n",
      "Weighted Accuracy: 94.19%\n",
      "Accuracy: 94.06%\n",
      "Time per prediction: 0.8235238524575772 ms\n",
      "Size (bytes): 1.45MB\n",
      "--------------------------------------------------\n",
      "rfc1\n",
      "Weighted Accuracy: 93.49%\n",
      "Accuracy: 93.54%\n",
      "Time per prediction: 0.03611661564369432 ms\n",
      "Size (bytes): 42.64MB\n",
      "--------------------------------------------------\n",
      "rfc2\n",
      "Weighted Accuracy: 93.55%\n",
      "Accuracy: 93.88%\n",
      "Time per prediction: 0.0357818849943097 ms\n",
      "Size (bytes): 40.73MB\n",
      "--------------------------------------------------\n",
      "rfc3\n",
      "Weighted Accuracy: 93.1%\n",
      "Accuracy: 93.45%\n",
      "Time per prediction: 0.09048796233999432 ms\n",
      "Size (bytes): 107.59MB\n",
      "--------------------------------------------------\n",
      "svm1\n",
      "Weighted Accuracy: 97.94%\n",
      "Accuracy: 97.33%\n",
      "Time per prediction: 0.08170816222723962 ms\n",
      "Size (bytes): 826.17KB\n",
      "--------------------------------------------------\n",
      "svm2\n",
      "Weighted Accuracy: 97.85%\n",
      "Accuracy: 97.24%\n",
      "Time per prediction: 0.07521089657332546 ms\n",
      "Size (bytes): 792.22KB\n",
      "--------------------------------------------------\n",
      "svm3\n",
      "Weighted Accuracy: 97.88%\n",
      "Accuracy: 97.33%\n",
      "Time per prediction: 0.07788032216311117 ms\n",
      "Size (bytes): 799.14KB\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    print_metrics(model, train_data, test_data)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of performance, the SVM 1 model is by far the best, with a score of 97.94% It also very good accuracy and time per prediction, being able to predict the label in less than 0.1 milisecond. They also require less than 1 MB of disk space to be storaged, so they can easily be downloaded in most applications.\n",
    "\n",
    "The KNN models presented no advantage over the SVM models, therefore they're probably not interesing choices. The random forest 1 and 2 models, however, even though have low accuracies scores compared to the other models, can make prediction extremely fast, so depending on the application, they can be a good choice. However, they do require more disk space to be stored than the other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
